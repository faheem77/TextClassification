{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# load dataset of sms messages\n",
    "\n",
    "df =pd.read_csv('SPAM text message 20170820 - Data.csv', header=None, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "0    5572 non-null object\n",
      "1    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n",
      "None\n",
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# Print useful information from dataset\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    " # check class distribution\n",
    "classes = df[0]\n",
    "print(classes.value_counts())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 2. Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     ham\n",
      "1     ham\n",
      "2    spam\n",
      "3     ham\n",
      "4     ham\n",
      "5    spam\n",
      "6     ham\n",
      "7     ham\n",
      "8    spam\n",
      "9    spam\n",
      "Name: 0, dtype: object\n",
      "[0 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Convert class labels into binary 0=ham , 1=spam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(classes)\n",
    "print(classes[:10])\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "5    FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "7    As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    WINNER!! As a valued network customer you have...\n",
      "9    Had your mobile 11 months or more? U R entitle...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Store SMS Data\n",
    "text_messages = df[1]\n",
    "print(text_messages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regular expression to replace email addressses, phone numbers, numbers, other numbers, symbols\n",
    "\n",
    "# email addresses with 'emailadr'\n",
    "\n",
    "processed = text_messages.str.replace(r'^.+@[^\\.], *\\,[a-z]{2}$', 'emailaddr')\n",
    "\n",
    "# replace urls with 'webaddress'\n",
    "\n",
    "processed = processed.str.replace(r' ^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\$+)7$', 'webaddress')\n",
    "\n",
    "\n",
    "# replace money symbols with 'moneysymb'\n",
    "processed = processed.str.replace(r' £|\\$', 'moneysymb')\n",
    "\n",
    "# replace 10 digits phone numbers with simply 'phonenumber'\n",
    "\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\d]{3}[\\s-]?[\\d]{4}$', 'phonenumber')\n",
    "\n",
    "# replace number with 'number'\n",
    "\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "\n",
    "processed= processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# replace whitespace btween term with single space\n",
    "\n",
    "processed = processed.str.replace(r' \\s+', ' ')\n",
    "\n",
    "# removing leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+7$', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    go until jurong point crazy available only in ...\n",
      "1                             ok lar joking wif u oni \n",
      "2    free entry in number a wkly comp to win fa cup...\n",
      "3         u dun say so early hor u c already then say \n",
      "4    nah i don t think he goes to usf he lives arou...\n",
      "5    freemsg hey there darling it s been number wee...\n",
      "6    even my brother is not like to speak with me t...\n",
      "7    as per your request melle melle oru minnaminun...\n",
      "8    winner as a valued network customer you have b...\n",
      "9    had your mobile number months or more u r enti...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# change the word hello,HELLO, Hello all are same words\n",
    "\n",
    "processed= processed.str.lower()\n",
    "\n",
    "print(processed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words from the text messages.\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "processed = processed.apply(lambda x: ' '. join(term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words stem usign Porter stemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x: ' '. join(ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go jurong point crazi avail bugi n great world...\n",
      "1                                   ok lar joke wif u oni\n",
      "2       free entri number wkli comp win fa cup final t...\n",
      "3                     u dun say earli hor u c alreadi say\n",
      "4                    nah think goe usf live around though\n",
      "5       freemsg hey darl number week word back like fu...\n",
      "6           even brother like speak treat like aid patent\n",
      "7       per request mell mell oru minnaminungint nurun...\n",
      "8       winner valu network custom select receiveamone...\n",
      "9       mobil number month u r entitl updat latest col...\n",
      "10      gonna home soon want talk stuff anymor tonight...\n",
      "11      six chanc win cash number number number pound ...\n",
      "12      urgent number week free membership ourmoneysym...\n",
      "13      search right word thank breather promis wont t...\n",
      "14                                            date sunday\n",
      "15      xxxmobilemovieclub use credit click wap link n...\n",
      "16                                             oh k watch\n",
      "17      eh u rememb number spell name ye v naughti mak...\n",
      "18                             fine way u feel way gota b\n",
      "19      england v macedonia dont miss goal team news t...\n",
      "20                                     serious spell name\n",
      "21                         go tri number month ha ha joke\n",
      "22                         ü pay first lar da stock comin\n",
      "23      aft finish lunch go str lor ard number smth lo...\n",
      "24                     ffffffffff alright way meet sooner\n",
      "25      forc eat slice realli hungri tho suck mark get...\n",
      "26                                      lol alway convinc\n",
      "27      catch bu fri egg make tea eat mom left dinner ...\n",
      "28                        back amp pack car let know room\n",
      "29                    ahhh work vagu rememb feel like lol\n",
      "                              ...                        \n",
      "5542                           armand say get ass epsilon\n",
      "5543                  u still havent got urself jacket ah\n",
      "5544    take derek amp taylor walmart back time done l...\n",
      "5545                               hi durban still number\n",
      "5546                               ic lotta childporn car\n",
      "5547    contract mobil number mnth latest motorola nok...\n",
      "5548                                        tri weekend v\n",
      "5549    know wot peopl wear shirt jumper hat belt know...\n",
      "5550                                  cool time think get\n",
      "5551                           wen get spiritu deep great\n",
      "5552    safe trip nigeria wish happi soon compani shar...\n",
      "5553                                hahaha use brain dear\n",
      "5554    well keep mind got enough ga one round trip ba...\n",
      "5555    yeh indian nice tho kane bit shud go number dr...\n",
      "5556                            ye u text pshew miss much\n",
      "5557    meant calcul lt gt unit lt gt school realli ex...\n",
      "5558                                     sorri call later\n",
      "5559                       next lt gt hour imma flip shit\n",
      "5560                                 anyth lor juz us lor\n",
      "5561                get dump heap mom decid come low bore\n",
      "5562    ok lor soni ericsson salesman ask shuhui say q...\n",
      "5563                              ard number like dat lor\n",
      "5564                     wait til least wednesday see get\n",
      "5565                                              huh lei\n",
      "5566    remind onumb get number pound free call credit...\n",
      "5567    numbernd time tri number contact u u themoneys...\n",
      "5568                              ü b go esplanad fr home\n",
      "5569                                    piti mood suggest\n",
      "5570    guy bitch act like interest buy someth els nex...\n",
      "5571                                       rofl true name\n",
      "Name: 1, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#creatig a bag-of-words model\n",
    "all_words = []\n",
    "\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 6613\n",
      "Most common words: [('number', 2769), ('u', 1203), ('call', 675), ('go', 456), ('get', 452), ('ur', 383), ('gt', 318), ('lt', 316), ('come', 304), ('ok', 293), ('free', 284), ('day', 276), ('know', 275), ('love', 266), ('like', 261)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print the total numbers of words and 15 most common words\n",
    "print('Number of words: {}'.format(len(all_words)))\n",
    "print ('Most common words: {}'. format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 1500 most common words as feature\n",
    "word_features = list(all_words.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "# define find_features functions\n",
    "def  find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "        \n",
    "        return features\n",
    "# lets see an example\n",
    "features = find_features(processed[0])\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
